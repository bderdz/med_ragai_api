# üë®‚Äç‚öïÔ∏è Medical Diagnosis RAG Assistant

<div align="center">

![Python](https://img.shields.io/badge/Python-3.11-3776AB?logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.121-009688?logo=fastapi&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-v1.0-1C3C3C?logo=langchain&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-GHCR-blue?logo=docker&logoColor=white)

![Gemini](https://img.shields.io/badge/Google%20AI-Gemini%20Flash-8E75B2?logo=google&logoColor=white)
![HuggingFace](https://img.shields.io/badge/HuggingFace-Models-FFD21E?logo=huggingface&logoColor=black)

![Status](https://img.shields.io/badge/Status-Educational-yellow)
![License](https://img.shields.io/badge/License-MIT-green)

</div>

**A Retrieval-Augmented Generation (RAG) based medical diagnosis assistant
designed to provide medical diagnosis suggestions based on patient symptoms, age and gender**
using a combination of a local vector database (`ChromaDB`), a local reranking model,
and reasoning LLM Gemini model via API.

Project is built with Fast API as main backend part and a simple chat wrapper around it
for project showcase, only for the needs of the subject **IBM LLM-Basic**.

## üîé Overview

**This project created for 2 university subjects:**

1. **Medical information systems:** Main API implementation of medical diagnosis assistant.
2. **IBM LLM-Basic:** A chat wrapper around the API with local LLM model for collecting patient information.

### üõ†Ô∏è Tech Stack:

- **Package Manager:** [uv](https://docs.astral.sh/uv/)
- **Backend:** `FastAPI`
- **Chat Frontend:** `Gradio`
- **LLM Framework:** `LangChain`
- **Vector Store:** `ChromaDB`
- **LLM Models:**
    - **Main Reasoning:** `gemini-2.5-flash` (via API)
    - **Chat Agent:** `Qwen2.5-0.5B-Instruct` (Local)
    - **Embedding:** `all-MiniLM-L6-v2`
    - **Reranking:** `MiniLM-L6-v2`
- **Testing**: `Pytest`
- **Logging:** `logging`
- **Data Handling:** `Pandas`, `NumPy`, `Pydantic`

### üìö Disease Dataset:

The disease dataset used in this project is sourced from:
[A Structured Bangla Dataset of Disease-Symptom Associations](https://data.mendeley.com/datasets/rjgjh8hgrt/5)

üëâ **Preprocessing steps are available here:** [Dataset Processing Notebook](https://github.com/bderdz/disease_icd_dataset)

### ‚öôÔ∏è Architecture Overview:

1. **Backend API (FastAPI)**

   Acts as the main entry point of the system. It **receives patient data (symptoms, age, gender)**,
   **validates input using Pydantic schemas**, and orchestrates the **diagnosis pipeline**.
2. **Retrieval (ChromaDB + Embeddings)**

   Disease profiles are embedded using the `all-MiniLM-L6-v2` model and
   stored in a local ChromaDB vector database. Relevant disease candidates are retrieved based on **semantic similarity to patient symptoms**.
3. **Reranking (CrossEncoder)**

   Retrieved documents are reranked using a local `MiniLM-L6-v2` CrossEncoder model
   to improve retrieval precision.

   **The top-K reranked documents are selected as context for reasoning model.**
4. **Reasoning (Gemini API)**

   The final diagnosis is generated by the `gemini-2.5-flash` model via API, using the
   patient data and retrieved medical context.
5. **Chat Interface (Gradio)**

   A lightweight chat wrapper using a local LLM `Qwen2.5-0.5B-Instruct` is used to **collect
   patient information** and **communicate with the API by using tool**.

### üîí Guardrails:

Since the project interacts with medical data and LLMs, security and safety are prioritized.
The following guardrails are implemented:

- **Prompt injection protection**
- **Sensitive data detection**
- **Links and profanity filtering**
- **Tool usage validation**
- **Structured output**

## üöÄ Getting Started

üëâ Follow these steps to setup and run the project Locally or with Docker.

### Initial Setup (Required)

Before running the project, you need to clone the repository **(if running Locally)** and configure
the environment variables **(Both Locally and Docker)**.

1. **Clone the repository:**

```bash
git clone https://github.com/bderdz/med_rag_assistant.git
cd med_ragai_api
```

2. ‚ùó **Configure environment variables:**

**Create a `.env` file in the root directory** (based on `.env.example`) and set your
API key.

‚ö†Ô∏è **NOTE: It's recommended not to change default LLM and Embedding models to ensure better performance.**

```ini
GOOGLE_API_KEY = YOUR_API_KEY_HERE
# Add other variables from .env.example here if you want to change defaults
# ...
```

### üê≥ Run with Docker

Run the application immediately using the pre-built image from GitHub Container Registry.

```bash
# Run Docker container with environment variables from .env file
docker run -p 8000:8000 --env-file .env ghcr.io/bderdz/med_rag_assistant:latest
```

### üõ†Ô∏è Run Locally (Development)

1. **Install dependencies using `uv` (Recommended)**

```bash
# Install UV if you don't have it yet
pip install uv

# Sync dependencies
uv sync
```

2. **Activate the environment:**

```bash
source .venv/bin/activate
```

**or run files with `uv` directly:**

```bash
uv run <file_name>.py
```

3. **Start the App:**

```bash
uv run uvicorn main:app --host 0.0.0.0 --port 8000
```

4. **Access the App**

Once the server is running, the API will be available at:

- **API and Chat Interface:** http://localhost:8000
- **API Docs (Swagger UI):** http://localhost:8000/docs

## üî¨ Evaluation

1. **Recall@K** evaluation used to evaluate the performance of the retrieval and reranking.

`evaluate.py` script runs the evaluation with provided **Top-K and sample size parameters** on the
test set **with and without reranking**.
To run the evaluation, use the following command at the project root directory:

```bash
uv run evaluate.py
```

2. **LLM Models metrics** such as **latency and token usage** automatically logged into `logs/metrics.log` file during API usage.

## ‚úÖ Tests

To run tests, use the following command at the project root directory:

```bash
# Default test run
uv run pytest
# Run tests and save results to a txt file
uv run pytest > logs/test_results.txt
```

*Tests logs will be saved in the `logs/pytest.log` file.*

1. API: `tests/test_api.py` - Tests for API, request validation and response structure.
2. Tool parser: `tests/test_parser.py` - Tests JSON parsing and error handling in the tool parser.
3. Dispatcher: `tests/test_dispatcher.py` - Tests timeouts, allowed tools validation and error handling in the dispatcher.
4. Guardrails: `tests/test_guardrails.py` - Tests for guardrails validation and error handling.